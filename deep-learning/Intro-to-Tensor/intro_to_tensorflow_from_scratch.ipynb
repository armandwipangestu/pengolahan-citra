{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning - Intro to TensorFlow from Scratch\n",
        "\n",
        "- Nama            : Arman Dwi Pangestu\n",
        "- NIM             : 1221604\n",
        "- Program Studi   : Teknik Informatika\n",
        "- Semester        : 7 Antara (Ganjil)\n",
        "- Mata Kuliah     : Deep Learning\n",
        "- Dosen           : Mina Ismu Rahayu\n",
        "- Tugas           : Tugas 1 - Eksplorasi TensorFlow from Scracth\n",
        "- Tanggal         : Minggu, 28 Juli 2024"
      ],
      "metadata": {
        "id": "MqBOQSRaKvpI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoL9AIgQrOvo"
      },
      "source": [
        "<h1 align=\"center\">TensorFlow Neural Network Lab</h1>\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKKdGFXMrOvu"
      },
      "source": [
        "<img src=\"image/notmnist.png\">\n",
        "In this lab, you'll use all the tools you learned from *Introduction to TensorFlow* to label images of English letters! The data you are using, <a href=\"http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html\">notMNIST</a>, consists of images of a letter from A to J in different fonts.\n",
        "\n",
        "The above images are a few examples of the data you'll be training on. After training the network, you will compare your prediction model against test data. Your goal, by the end of this lab, is to make predictions against that test set with at least an 80% accuracy. Let's jump in!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Eksplorasi**: Pada lab kali ini, saya akan menggunakan semua tools untuk belajar dari *pengenalan pada TensorFlow* untuk melakukan labeling gambar dari huruf bahasa inggris, data yang akan digunakan berasal dari notMNIST, yang mengandung gambar berupa huruf dari A sampai J dengan font yang berbeda-beda.\n",
        "\n",
        "> **Eksplorasi**: Gambar diatas adalah beberapa contoh data yang akan saya lakukan training. Setelah jaringan/network di training, saya akan melakukan perbandingan dengan prediction model dengan data testing. Tujuan saya, pada akhir lab ini, adalah membuat prediksi dengan data test yang di set dengan akurasi setidaknya sebanyak 80%."
      ],
      "metadata": {
        "id": "z2MXZXUFNqMl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgLUMShzrOvw"
      },
      "source": [
        "To start this lab, you first need to import all the necessary modules. Run the code below. If it runs successfully, it will print \"`All modules imported`\"."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Eksplorasi**: Untuk memulai nya, saya perlu melakukan import semua module yang dibutuhkan. Untuk melakukannya jalankan code dibawah ini"
      ],
      "metadata": {
        "id": "gKv6Z96WOb1w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1FlLwL5GrOvx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "910bbc54-4862-496a-e478-358951dd29e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All modules imported.\n"
          ]
        }
      ],
      "source": [
        "import hashlib\n",
        "import os\n",
        "import pickle\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.utils import resample\n",
        "from tqdm import tqdm\n",
        "from zipfile import ZipFile\n",
        "\n",
        "print('All modules imported.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YOkXGpzrOvz"
      },
      "source": [
        "The notMNIST dataset is too large for many computers to handle.  It contains 500,000 images for just training.  You'll be using a subset of this data, 15,000 images for each label (A-J)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Eksplorasi**: dataset notMNIST terlalu banyak untuk beberapa komputer yang akan menghandle nya. Dataset tersebut mengandung 500,000 gambar hanya untuk training. Saya akan menggunakan subset dari data tersebut sebesar 15,000 gambar untuk setiap label (A-J)\n",
        "\n",
        "> **Eksplorasi**: Untuk melakukannya pertama disini kita download terlebih dahulu dataset notMNIST nya menggunakan library `urlretrieve` setelah itu kita lakukan pengecekan checksum file nya apakah sama atau tidak, jika tidak sama maka file tersebut corrupt."
      ],
      "metadata": {
        "id": "93Q3IBHYO2fB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t1fkofQnrOvz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e000b6e6-0eb2-48da-834f-d4f914c3047e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading notMNIST_train.zip...\n",
            "Download Finished\n",
            "Downloading notMNIST_test.zip...\n",
            "Download Finished\n",
            "All files downloaded.\n"
          ]
        }
      ],
      "source": [
        "def download(url, file):\n",
        "    \"\"\"\n",
        "    Download file from <url>\n",
        "    :param url: URL to file\n",
        "    :param file: Local file path\n",
        "    \"\"\"\n",
        "    if not os.path.isfile(file):\n",
        "        print('Downloading ' + file + '...')\n",
        "        urlretrieve(url, file)\n",
        "        print('Download Finished')\n",
        "\n",
        "# Download the training and test dataset.\n",
        "download('https://s3.amazonaws.com/udacity-sdc/notMNIST_train.zip', 'notMNIST_train.zip')\n",
        "download('https://s3.amazonaws.com/udacity-sdc/notMNIST_test.zip', 'notMNIST_test.zip')\n",
        "\n",
        "# Make sure the files aren't corrupted\n",
        "assert hashlib.md5(open('notMNIST_train.zip', 'rb').read()).hexdigest() == 'c8673b3f28f489e9cdf3a3d74e2ac8fa',\\\n",
        "        'notMNIST_train.zip file is corrupted.  Remove the file and try again.'\n",
        "assert hashlib.md5(open('notMNIST_test.zip', 'rb').read()).hexdigest() == '5d3c7e653e63471c88df796156a9dfa9',\\\n",
        "        'notMNIST_test.zip file is corrupted.  Remove the file and try again.'\n",
        "\n",
        "# Wait until you see that all files have been downloaded.\n",
        "print('All files downloaded.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Eksplorasi**: Setelah file berhasil di download dan dilakukan pengecekan checksum, selanjutnya dilakukan uncompress/unzip file dataset tersebut menggunakan library `ZipFile` dan library `tqdm` untuk memunculkan progress bar\n",
        "\n",
        "> **NOTE**: Feature adalah data dari gambar yang diload, biasanya berupa angka-angka yang merepresentasikan warna-warna pada setiap pixel nya (jika RGB maka bentuknya 3 dimensi yaitu RGB), kemudian data tersebut di konversi menjadi array 1 dimensi atau biasa disebut dengan flatten dan disimpan ke memori dengan tipe data float32\n",
        "\n",
        "> 1. Buat function untuk melakukan pengecekan saat proses uncompress/unzip apakah yang dicek isinya file atau directory\n",
        "> 2. Jika file maka simpan kedalam feature dengan cara load image data nya menjadi array 1 dimensi (`flatten`) dengan tipe data `float32` pada memory nya\n",
        "> 3. Setelah feature nya diambil, sekarang ambil data label huruf dari gambar tersebut\n",
        "> 4. Selanjutnya simpan data feature dan label tersebut kedalam array kosong\n",
        "> 5. Return dari function tersebut dengan data array feature dan label\n",
        "> 6. Selanjutnya buat 2 buah variable `train_features`, `train_labels` dan `test_features`, `test_labels` untuk menyimpan data train dan juga data test dari dataset notMNIST, kemudian isikan variable tersebut dengan cara memanggil function yang sudah dibuat\n",
        "> 7. Selanjutnya lakukan `resample` dataset train notMNIST tersebut yang berisi `500,000` gambar menjadi `15,000`\n",
        "> 8. Selanjutnya buat inisialisasi variable `is_fetatures_normal` dan `is_labels_encod` untuk state pada data pre-processing"
      ],
      "metadata": {
        "id": "7x-NMHAaPrHh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qVBZ8Sh3rOv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e38d4289-731d-4ea8-eb4f-e75f782f99e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 210001/210001 [00:45<00:00, 4580.32files/s]\n",
            "100%|██████████| 10001/10001 [00:02<00:00, 3987.08files/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All features and labels uncompressed.\n"
          ]
        }
      ],
      "source": [
        "def uncompress_features_labels(file):\n",
        "    \"\"\"\n",
        "    Uncompress features and labels from a zip file\n",
        "    :param file: The zip file to extract the data from\n",
        "    \"\"\"\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    with ZipFile(file) as zipf:\n",
        "        # Progress Bar\n",
        "        filenames_pbar = tqdm(zipf.namelist(), unit='files')\n",
        "\n",
        "        # Get features and labels from all files\n",
        "        for filename in filenames_pbar:\n",
        "            # Check if the file is a directory\n",
        "            if not filename.endswith('/'):\n",
        "                with zipf.open(filename) as image_file:\n",
        "                    image = Image.open(image_file)\n",
        "                    image.load()\n",
        "                    # Load image data as 1 dimensional array\n",
        "                    # We're using float32 to save on memory space\n",
        "                    feature = np.array(image, dtype=np.float32).flatten()\n",
        "\n",
        "                # Get the the letter from the filename.  This is the letter of the image.\n",
        "                label = os.path.split(filename)[1][0]\n",
        "\n",
        "                features.append(feature)\n",
        "                labels.append(label)\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# Get the features and labels from the zip files\n",
        "train_features, train_labels = uncompress_features_labels('notMNIST_train.zip')\n",
        "test_features, test_labels = uncompress_features_labels('notMNIST_test.zip')\n",
        "\n",
        "# Limit the amount of data to work with a docker container\n",
        "docker_size_limit = 150000\n",
        "train_features, train_labels = resample(train_features, train_labels, n_samples=docker_size_limit)\n",
        "\n",
        "# Set flags for feature engineering.  This will prevent you from skipping an important step.\n",
        "is_features_normal = False\n",
        "is_labels_encod = False\n",
        "\n",
        "# Wait until you see that all features and labels have been uncompressed.\n",
        "print('All features and labels uncompressed.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDrD3Dh5rOv3"
      },
      "source": [
        "<img src=\"image/Mean_Variance_Image.png\" style=\"height: 75%;width: 75%; position: relative; right: 5%\">\n",
        "## Problem 1\n",
        "The first problem involves normalizing the features for your training and test data.\n",
        "\n",
        "Implement Min-Max scaling in the `normalize_grayscale()` function to a range of `a=0.1` and `b=0.9`. After scaling, the values of the pixels in the input data should range from 0.1 to 0.9.\n",
        "\n",
        "Since the raw notMNIST image data is in [grayscale](https://en.wikipedia.org/wiki/Grayscale), the current values range from a min of 0 to a max of 255.\n",
        "\n",
        "Min-Max Scaling:\n",
        "$\n",
        "X'=a+{\\frac {\\left(X-X_{\\min }\\right)\\left(b-a\\right)}{X_{\\max }-X_{\\min }}}\n",
        "$\n",
        "\n",
        "*If you're having trouble solving problem 1, you can view the solution [here](https://github.com/udacity/deep-learning/blob/master/intro-to-tensorflow/intro_to_tensorflow_solution.ipynb).*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Eksplorasi**: Problem 1: Problem pertama adalah melibatkan normalisasi feature dari data training dan test.\n",
        "> Implementasi Min-Max scaling pada function `normalize_grayscale()` untuk sebuah rentang dari `a=0.1` dan `b=0.9`. Setelah scaling, value dari pixel input data harus berada pada rentang `0.1` dan `0.9`.\n",
        "> Dikarenakan raw data dari dataset gambar notMNIST adalah data `grayscale`, maka rentang value nya berada di minimum `0` dan maximum `255`.\n",
        ">\n",
        "> Rumus dari Min-Max Scaling adalah:\n",
        "> $\n",
        "> X'=a+{\\frac {\\left(X-X_{\\min }\\right)\\left(b-a\\right)}{X_{\\max }-X_{\\min }}}\n",
        "> $\n",
        ">\n",
        "> 1. Buat function dengan nama `normalize_grayscale(image_data)` yang menerima data feature dari gambar yang sudah di flatten sebelumnya\n",
        "> 2. Lakukan operasi dari rumus Min-Max Scaling diatas pada isian dari function tersebut dengan cara mendefinisikan beberapa variable yang diperlukan seperti, nilai range untuk `a` dan `b` yang diinginkan adalah `0.1` dan `0.9`. Selanjutnya definisikan juga nilai `X_min` dan `X_max` dari original data nya (dikarenakan pada kasus ini menggunakan data grayscale dari notMNIST dan sudah di flatten maka value nya sekitar `0` hingga `255`\n",
        "> 3. Setelah mendefinisikan variabel-variabel yang dibutuhkan selanjutnya lakukan kalkulasi atau perhitungan berdasarkan rumus Min-Max Scaling tersebut dan jika sudah selesai maka lakukan return data nya\n",
        "> 4. Selanjutnya lakukan uji kasus apakah function nya sudah sesuai yang diharapkan berdasarkan rumus Min-Max scaling tersebut, lakukan dengan sample data menggunakan numpy testing dan `assert_array_almost_equal`, parameter pertama berikan sampel data array 1 dimensi (sebagai sample data yang sudah di `flatten`), selanjutnya pada parameter kedua berikan sample value kisaran data yang mungkin mendekati dari hasil normalisasi grayscale dari rumus Min-Max scaling tersebut.\n",
        "> 5. Jika normal, maka sekarang lakukan normalisasi untuk data `training_features` dan `test_features`"
      ],
      "metadata": {
        "id": "27JcSte_VfGw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w6XwoJCgrOv4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "177c55f2-dcc4-4f71-8f1b-60c132a06d47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tests Passed!\n"
          ]
        }
      ],
      "source": [
        "# Problem 1 - Implement Min-Max scaling for grayscale image data\n",
        "def normalize_grayscale(image_data):\n",
        "    \"\"\"\n",
        "    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
        "    :param image_data: The image data to be normalized\n",
        "    :return: Normalized image data\n",
        "    \"\"\"\n",
        "    # TODO: Implement Min-Max scaling for grayscale image data\n",
        "    # Rumus dari Min-Max Scaling: X'=a+{\\frac {\\left(X-X_{\\min }\\right)\\left(b-a\\right)}{X_{\\max }-X_{\\min }}}\n",
        "    # Min dan Max values untuk range yang diinginkan\n",
        "    a = 0.1\n",
        "    b = 0.9\n",
        "\n",
        "    # Min and Max values untuk original data (data feature yang sudah di flatten)\n",
        "    X_min = 0\n",
        "    X_max = 255\n",
        "\n",
        "    # Melakukan perhitungan atau kalkulasi untuk Min-Max scaling\n",
        "    X_prime = a + ((image_data - X_min) * (b - a)) / (X_max - X_min)\n",
        "\n",
        "    return X_prime\n",
        "\n",
        "\n",
        "### DON'T MODIFY ANYTHING BELOW ###\n",
        "# Test Cases\n",
        "np.testing.assert_array_almost_equal(\n",
        "    normalize_grayscale(np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 255])),\n",
        "    [0.1, 0.103137254902, 0.106274509804, 0.109411764706, 0.112549019608, 0.11568627451, 0.118823529412, 0.121960784314,\n",
        "     0.125098039216, 0.128235294118, 0.13137254902, 0.9],\n",
        "    decimal=3)\n",
        "np.testing.assert_array_almost_equal(\n",
        "    normalize_grayscale(np.array([0, 1, 10, 20, 30, 40, 233, 244, 254,255])),\n",
        "    [0.1, 0.103137254902, 0.13137254902, 0.162745098039, 0.194117647059, 0.225490196078, 0.830980392157, 0.865490196078,\n",
        "     0.896862745098, 0.9])\n",
        "\n",
        "if not is_features_normal:\n",
        "    train_features = normalize_grayscale(train_features)\n",
        "    test_features = normalize_grayscale(test_features)\n",
        "    is_features_normal = True\n",
        "\n",
        "print('Tests Passed!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Eksplorasi**: Setelah melakukan normalisasi grayscale pada data feature, selanjutnya kita lakukan konversi atau transform atau ubah data label menjadi binary dengan One-Hot Encoding\n",
        ">\n",
        "> Sebagai contoh, data label yang digunakan adalah berisi kategorikal seperti `A, B, C, ..., J`. Nah, data tersebut rupanya sulit untuk dipahami oleh model machine learning atau deep learning pada saat proses pemilihan fully-connected layer output atau dense layer output seperti menggunakan algoritma softmax. Oleh karena itu, kita perlu mengubah data label tersebut menjadi numerical, seperti misalkan A, B, C. Maka `A = [1, 0, 0]`, `B = [0, 1, 0]`, dan `C = [0, 0, 1]`"
      ],
      "metadata": {
        "id": "AO9oypY9dlJb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d0eYlGv2rOv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40e84234-ddc1-49d2-8d73-a992d23c3917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels One-Hot Encoded\n"
          ]
        }
      ],
      "source": [
        "if not is_labels_encod:\n",
        "    # Turn labels into numbers and apply One-Hot Encoding\n",
        "    encoder = LabelBinarizer()\n",
        "    encoder.fit(train_labels)\n",
        "    train_labels = encoder.transform(train_labels)\n",
        "    test_labels = encoder.transform(test_labels)\n",
        "\n",
        "    # Change to float32, so it can be multiplied against the features in TensorFlow, which are float32\n",
        "    train_labels = train_labels.astype(np.float32)\n",
        "    test_labels = test_labels.astype(np.float32)\n",
        "    is_labels_encod = True\n",
        "\n",
        "print('Labels One-Hot Encoded')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Eksplorasi**: Setelah proses normalisasi grayscale dan transform label menjadi binary. Selanjutnya melakukan proses Randomize dan split dataset untuk training dan validation. Mengapa hal ini diperlukan?\n",
        "> 1. **Menghindari overfitting**: Memiliki set data terpisah untuk pelatihan (training) dan validasi (validation) memungkinkan kita memeriksa apakah model kita hanya menghafal data pelatihan atau benar-benar belajar pola yang dapat digeneralisasikan ke data baru. Tanpa pemisahan ini, kita tidak dapat menilai kinerja model pada data yang belum pernah dilihat sebelumnya.\n",
        "> 2. **Meningkatkan Generalisasi**: Dengan membagi dataset menjadi bagian training dan validation, kita bisa memastikan bahwa model kita belajar dari data yang representatif dari seluruh dataset, bukan hanya dari subset tertentu. Ini membantu model untuk lebih baik dalam mengeneralisasi ke data yang tidak terlihat.\n",
        "> 3. **Menyediakan Evaluasi yang Akurat**: Validasi selama pelatihan memberikan kita pandangan tentang bagaimana model kita berkinerja pada data yang tidak dilihat selama pelatihan. Ini membantu kita mengatur hyperparameter model dan memilih model terbaik berdasarkan kinerja pada data validation.\n",
        ">\n",
        "> **NOTE**:\n",
        "> 1. parameter `test_size=0.05` artinya adalah kita menentukan proporsi data yang akan digunakan untuk set validasi. Artinya, `5%` dari data akan digunakan untuk validasi dan `95%` untuk pelatihan.\n",
        "> 2. parameter `random_state=832289` adalah seed untuk generator angka acak yang digunakan untuk memastikan bahwa pemisahan dataset dapat direproduksi. Ini berarti setiap kali Anda menjalankan kode, pemisahan akan sama, yang penting untuk konsistensi dalam eksperimen dan pelaporan.\n",
        ">\n",
        "> **Bagaimana Cara Kerja Random State?**\n",
        "> Misalkan kita memiliki dataset yang terdiri dari `10` angka, yaitu `1` sampai `10`. Sekarang, jika kita ingin membaginya menjadi dataset pelatihan dan pengujian, dengan ukuran dataset pengujian sebesar `20%` dari keseluruhan dataset, maka dataset pelatihan akan terdiri dari `8` sampel data, sedangkan dataset pengujian akan terdiri dari `2` sampel data.\n",
        ">\n",
        "> Penting untuk memastikan bahwa proses pengacakan dataset menghasilkan hasil yang konsisten setiap saat, sehingga kode dapat direproduksi. Tanpa pengacakan dataset, setiap eksekusi kode dapat menghasilkan dataset yang berbeda, yang tidak ideal untuk melatih model karena setiap latihan menggunakan data yang berbeda. Oleh karena itu, setiap kali kita ingin mengacak dataset, kita menggunakan nilai `random_state`. Ini memastikan bahwa satu nilai `random_state` menghasilkan pengacakan yang konsisten, sehingga setiap kali kode dijalankan dengan nilai `random_state` yang sama, akan menghasilkan pembagian dataset yang serupa. Ini sangat penting utnuk memastikan konsistensi dalam percobaan dan evaluasi model."
      ],
      "metadata": {
        "id": "SFQSLF2DiRqI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4QVvGTMbrOv9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "210e326a-e2f1-400d-dfeb-9caa0c8c7a61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training features and labels randomized and split.\n"
          ]
        }
      ],
      "source": [
        "assert is_features_normal, 'You skipped the step to normalize the features'\n",
        "assert is_labels_encod, 'You skipped the step to One-Hot Encode the labels'\n",
        "\n",
        "# Get randomized datasets for training and validation\n",
        "train_features, valid_features, train_labels, valid_labels = train_test_split(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    test_size=0.05,\n",
        "    random_state=832289)\n",
        "\n",
        "print('Training features and labels randomized and split.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Eksplorasi**: Setelah melakukan randomize dan split data, selanjutnya kita perlu menyimpan data dalam bentuk pickle. Mengapa perlu melakukannya?\n",
        "> 1. **Akses yang cepat dan mudah**: Setelah melakukan pre-processing, seperti normalisasi feature dan one-hot encoding label, serta membagi dataset, proses ini bisa memakan waktu lama. Menyimpan data yang telah diproses dalam file pickle memungkinkan akses cepat dan mudah ke data ini tanpa harus mengulang langkah pre-processing setiap kali.\n",
        "> 2. **Konsistensi Data**: Dengan menyimpan data yang telah diproses, Anda memastikan bahwa setiap kali data di-load kembali, kondisinya tetap sama. Ini penting untuk konsistensi dalam eksperimen dan pelatihan model.\n",
        "> 3. **Menghemat waktu dan sumber daya**: Proses pre-processing dapat memakan banyak waktu dan sumber daya komputasi. Dengan menyimpan data yang telah diproses, Anda menghemat waktu dan sumber daya karena tidak perlu mengulang proses tersebut setiap kali ingin menggunakan data.\n",
        "> 4. **Keperluan pengembangan dan eksplorasi**: Saat mengembangkan dan mengeksplorasi model machine learning, Anda mungkin akan sering memuat dan mengubah data. Menyimpan data dalam bentuk pickle memungkinkan pengembang untuk fokus pada pengembangan model tanpa harus khawatir tentang pre-processing yang berulang."
      ],
      "metadata": {
        "id": "KRbcRSWM8eSA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ypiEvu-MrOv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "920a6494-5a75-4fd3-8c8d-7e5bacf24802"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data to pickle file...\n",
            "Data cached in pickle file.\n"
          ]
        }
      ],
      "source": [
        "# Save the data for easy access\n",
        "pickle_file = 'notMNIST.pickle'\n",
        "if not os.path.isfile(pickle_file):\n",
        "    print('Saving data to pickle file...')\n",
        "    try:\n",
        "        with open('notMNIST.pickle', 'wb') as pfile:\n",
        "            pickle.dump(\n",
        "                {\n",
        "                    'train_dataset': train_features,\n",
        "                    'train_labels': train_labels,\n",
        "                    'valid_dataset': valid_features,\n",
        "                    'valid_labels': valid_labels,\n",
        "                    'test_dataset': test_features,\n",
        "                    'test_labels': test_labels,\n",
        "                },\n",
        "                pfile, pickle.HIGHEST_PROTOCOL)\n",
        "    except Exception as e:\n",
        "        print('Unable to save data to', pickle_file, ':', e)\n",
        "        raise\n",
        "\n",
        "print('Data cached in pickle file.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJXSdySPrOv-"
      },
      "source": [
        "# Checkpoint\n",
        "All your progress is now saved to the pickle file.  If you need to leave and comeback to this lab, you no longer have to start from the beginning.  Just run the code block below and it will load all the data and modules required to proceed."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Eksplorasi**: Melakukan inisialisai variabel yang dibutuhkan berdasarkan atau menggunakan data yang sudah disimpan dengan pickle sehingga tidak perlu melakukan pre-processing seperti normalisasi, one-hot encoding label, serta membagi dataset."
      ],
      "metadata": {
        "id": "jLt6KUiJ-Tiy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ni8SvH0lrOv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f0be643-2893-47fd-fb42-01550d813a7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data and modules loaded.\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Load the modules\n",
        "import pickle\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reload the data\n",
        "pickle_file = 'notMNIST.pickle'\n",
        "with open(pickle_file, 'rb') as f:\n",
        "  pickle_data = pickle.load(f)\n",
        "  train_features = pickle_data['train_dataset']\n",
        "  train_labels = pickle_data['train_labels']\n",
        "  valid_features = pickle_data['valid_dataset']\n",
        "  valid_labels = pickle_data['valid_labels']\n",
        "  test_features = pickle_data['test_dataset']\n",
        "  test_labels = pickle_data['test_labels']\n",
        "  del pickle_data  # Free up memory\n",
        "\n",
        "print('Data and modules loaded.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN4WinncrOv_"
      },
      "source": [
        "\n",
        "## Problem 2\n",
        "\n",
        "Now it's time to build a simple neural network using TensorFlow. Here, your network will be just an input layer and an output layer.\n",
        "\n",
        "<img src=\"image/network_diagram.png\" style=\"height: 40%;width: 40%; position: relative; right: 10%\">\n",
        "\n",
        "For the input here the images have been flattened into a vector of $28 \\times 28 = 784$ features. Then, we're trying to predict the image digit so there are 10 output units, one for each label. Of course, feel free to add hidden layers if you want, but this notebook is built to guide you through a single layer network.\n",
        "\n",
        "For the neural network to train on your data, you need the following <a href=\"https://www.tensorflow.org/resources/dims_types.html#data-types\">float32</a> tensors:\n",
        " - `features`\n",
        "  - Placeholder tensor for feature data (`train_features`/`valid_features`/`test_features`)\n",
        " - `labels`\n",
        "  - Placeholder tensor for label data (`train_labels`/`valid_labels`/`test_labels`)\n",
        " - `weights`\n",
        "  - Variable Tensor with random numbers from a truncated normal distribution.\n",
        "    - See <a href=\"https://www.tensorflow.org/api_docs/python/constant_op.html#truncated_normal\">`tf.truncated_normal()` documentation</a> for help.\n",
        " - `biases`\n",
        "  - Variable Tensor with all zeros.\n",
        "    - See <a href=\"https://www.tensorflow.org/api_docs/python/constant_op.html#zeros\"> `tf.zeros()` documentation</a> for help.\n",
        "\n",
        "*If you're having trouble solving problem 2, review \"TensorFlow Linear Function\" section of the class.  If that doesn't help, the solution for this problem is available [here](intro_to_tensorflow_solution.ipynb).*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Eksplorasi**: Problem 2: Sekarang waktunya untuk membuat sebuah simpel neural network menggunakan TensorFlow. Disini, network saya akan hanya menggunakan input layer dan output layer.\n",
        ">\n",
        "> Untuk input disini gambar sudah di lakukan flattened atau diubah menjadi array 1 dimensi dengan vektor `28 x 28 = 748 features`. Lalu, kita mencoba melakukan prediksi dari angka gambar tersebut yang dimana terdapat 10 output units, satu untuk setiap label. Tentu, dengan bebas untuk menambahkan hidden layer jika kamu ingin, tapi pada notebook ini dibuat untuk menyontohkan kamu untuk satu buah single layer network.\n",
        ">\n",
        "> Untuk neural network agar bisa melakukan training di data kamu, kamu membutuhkan dengan mengikuti `float32` tensors\n",
        "> 1. `Features`\n",
        ">   - Placeholder tensor untuk feature data dari `train_features` / `valid_features` / `test_features`\n",
        "> 2. `Labels`\n",
        ">   - Placeholder tensor untuk label data dari `train_labels` / `valid_labels` / `test_labels`\n",
        "> 3. `Weights`\n",
        ">   - Variable tensor dengan angka acak dari sebuah truncated normal distribution.\n",
        ">     - `tf.truncated_normal()`\n",
        "> 4. `Biases`\n",
        ">   - Variable tensor dengan semua nol\n",
        ">     - `tf.zeros()`\n",
        ">\n",
        "> Implementasi simple neural network: input layer dan output layer\n",
        "> 1. Menetapkan placeholder untuk features dan labels\n",
        ">   - Placeholder digunakan untuk menyimpan data input (features) dan output (labels) saat menjalankan sesi TensorFlow.\n",
        ">   - Placeholder ini diisi saat sesi dijalankan dengan menggunakan `feed_dict`.\n",
        "> 2. Menetapkan Tensor untuk Weight dan Biases:\n",
        ">   - Weight dan biases adalah variabel TensorFlow yang akan diinisialisasi dan dioptimalkan selama pelatihan.\n",
        ">   - Weights menghubungkan input layer dengan output layer, dan biases menambahkan nilai konstan ke setiap neuron di output layer.\n",
        "> 3. Mengimplementasikan Fungsi Linear `WX + b` (activation function, summation and bias):\n",
        ">   - Ini adalah operasi dasar yang dilakukan oleh neuron di layer jaringan saraf\n",
        ">   - `logits` adalah hasil dari operasi ini sebelum activation function diterapkan.\n",
        "> 4. Menggunakan Fungsi Softmax untuk prediksi:\n",
        ">   - Fungsi Softmax mengubah logits menjadi probabilitas untuk setiap kelas di output layer.\n",
        "> 5. Menghitung Cross-Entropy Loss:\n",
        ">   - Cross-entropy loss digunakan untuk mengukur kesalahan antara prediksi model dan label sebenarnya.\n",
        "> 6. Menginisialisasi semua variabel:\n",
        ">   - Operasi inisialisasi variabel digunakan untuk menetapkan nilai awal untuk semua variabel TensorFlow."
      ],
      "metadata": {
        "id": "ygtOfYUI_oEG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "q5XBuuTErOv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e13625e8-00e7-4247-e673-dd96f8701258"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tests Passed!\n"
          ]
        }
      ],
      "source": [
        "# Disable eager execution to use TensorFlow 1.x functionality\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "# All the pixels in the image (28 * 28 = 784)\n",
        "features_count = 784\n",
        "# All the labels\n",
        "labels_count = 10\n",
        "\n",
        "# TODO: Set the features and labels tensors\n",
        "\"\"\" TensorFlow 1.x\n",
        "\"\"\"\n",
        "features = tf.compat.v1.placeholder(tf.float32, [None, features_count], name=\"features\")\n",
        "labels = tf.compat.v1.placeholder(tf.float32, [None, labels_count], name=\"labels\")\n",
        "\"\"\" TensorFlow 2.x\n",
        "features = tf.keras.Input(shape=(features_count,), name=\"features\")\n",
        "labels = tf.keras.Input(shape=(labels_count,), name=\"labels\")\n",
        "\"\"\"\n",
        "\n",
        "# TODO: Set the weights and biases tensors\n",
        "weights = tf.Variable(tf.random.truncated_normal([features_count, labels_count]), name=\"weights\")\n",
        "biases = tf.Variable(tf.zeros([labels_count]), name=\"biases\")\n",
        "\n",
        "### DON'T MODIFY ANYTHING BELOW ###\n",
        "\n",
        "#Test Cases\n",
        "from tensorflow.python.ops.variables import Variable\n",
        "\n",
        "\"\"\" TensorFlow 1.x\n",
        "\"\"\"\n",
        "#assert features._op.name.startswith('Placeholder'), 'features must be a placeholder'\n",
        "#assert labels._op.name.startswith('Placeholder'), 'labels must be a placeholder'\n",
        "assert features.op.type == 'Placeholder', 'features must be a placeholder'\n",
        "assert labels.op.type == 'Placeholder', 'labels must be a placeholder'\n",
        "assert isinstance(weights, Variable), 'weights must be a TensorFlow variable'\n",
        "assert isinstance(biases, Variable), 'biases must be a TensorFlow variable'\n",
        "\n",
        "\"\"\"\n",
        "assert features._shape == None or (\\\n",
        "    features._shape.dims[0].value is None and\\\n",
        "    features._shape.dims[1].value in [None, 784]), 'The shape of features is incorrect'\n",
        "assert labels._shape  == None or (\\\n",
        "    labels._shape.dims[0].value is None and\\\n",
        "    labels._shape.dims[1].value in [None, 10]), 'The shape of labels is incorrect'\n",
        "assert weights._variable._shape == (784, 10), 'The shape of weights is incorrect'\n",
        "assert biases._variable._shape == (10), 'The shape of biases is incorrect'\n",
        "\n",
        "assert features._dtype == tf.float32, 'features must be type float32'\n",
        "assert labels._dtype == tf.float32, 'labels must be type float32'\n",
        "\"\"\"\n",
        "\n",
        "\"\"\" TensorFlow 2.x\n",
        "assert isinstance(features, tf.Tensor), 'features must be a TensorFlow tensor'\n",
        "assert isinstance(labels, tf.Tensor), 'labels must be a TensorFlow tensor'\n",
        "assert isinstance(weights, tf.Variable), 'weights must be a TensorFlow variable'\n",
        "assert isinstnace(biases, tf.Variable), 'biases must be a TensorFlow variable'\n",
        "\"\"\"\n",
        "\n",
        "assert features.shape == (None, 784), 'The shape of features is incorrect'\n",
        "assert labels.shape == (None, 10), 'The shape of labels is incorrect'\n",
        "assert weights.shape == (784, 10), 'The shape of weights is incorrect'\n",
        "assert biases.shape == (10,), 'The shape of biases is incorrect'\n",
        "\n",
        "assert features.dtype == tf.float32, 'features must be type float32'\n",
        "assert labels.dtype == tf.float32, 'labels must be type float32'\n",
        "\n",
        "# Feed dicts for training, validation, and test session\n",
        "train_feed_dict = {features: train_features, labels: train_labels}\n",
        "valid_feed_dict = {features: valid_features, labels: valid_labels}\n",
        "test_feed_dict = {features: test_features, labels: test_labels}\n",
        "\n",
        "# Linear Function WX + b\n",
        "logits = tf.matmul(features, weights) + biases\n",
        "\n",
        "prediction = tf.nn.softmax(logits)\n",
        "\n",
        "# Cross entropy\n",
        "\"\"\" TensorFlow 1.x\n",
        "cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
        "\"\"\"\n",
        "\"\"\" TensorFlow 2.x\n",
        "\"\"\"\n",
        "cross_entropy = -tf.reduce_sum(labels * tf.math.log(prediction), axis=1)\n",
        "\n",
        "# Training loss\n",
        "loss = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "# Create an operation that initializes all variables\n",
        "\"\"\" TensorFlow 1.x\n",
        "init = tf.global_variables_initializer()\n",
        "\"\"\"\n",
        "\"\"\" TensorFlow 2.x\n",
        "\"\"\"\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "\n",
        "# Test Cases\n",
        "\"\"\" TensorFlow 1.x\n",
        "with tf.Session() as session:\n",
        "    session.run(init)\n",
        "    session.run(loss, feed_dict=train_feed_dict)\n",
        "    session.run(loss, feed_dict=valid_feed_dict)\n",
        "    session.run(loss, feed_dict=test_feed_dict)\n",
        "    biases_data = session.run(biases)\n",
        "\"\"\"\n",
        "\"\"\" TensorFlow 2.x\n",
        "\"\"\"\n",
        "with tf.compat.v1.Session() as session:\n",
        "    session.run(init)\n",
        "    session.run(loss, feed_dict=train_feed_dict)\n",
        "    session.run(loss, feed_dict=valid_feed_dict)\n",
        "    session.run(loss, feed_dict=test_feed_dict)\n",
        "    biases_data = session.run(biases)\n",
        "\n",
        "assert not np.count_nonzero(biases_data), 'biases must be zeros'\n",
        "\n",
        "print('Tests Passed!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Eksplorasi**: Setelah implementasi neural network nya, selanjutnya lakukan pengecekan apakah prediksi model nya benar atau tidak dengan membandingkan prediksi dengan label sebenarnya. Akurasi adalah metrik umum yang digunakan untuk mengevaluasi performa model klasifikasi, yang menunjukkan proporsi prediksi yang benar dari seluruh prediksi yang dibuat."
      ],
      "metadata": {
        "id": "1FPYsBvi1Ip9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iRZPhGf2rOwA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae1a23c8-be92-4d5d-9ed2-fbe7ec245616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy function created.\n"
          ]
        }
      ],
      "source": [
        "# Determine if the predictions are correct\n",
        "is_correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
        "# Calculate the accuracy of the predictions\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct_prediction, tf.float32))\n",
        "\n",
        "print('Accuracy function created.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk0-MfXmrOwA"
      },
      "source": [
        "<img src=\"image/Learn_Rate_Tune_Image.png\" style=\"height: 70%;width: 70%\">\n",
        "## Problem 3\n",
        "Below are 2 parameter configurations for training the neural network. In each configuration, one of the parameters has multiple options. For each configuration, choose the option that gives the best acccuracy.\n",
        "\n",
        "Parameter configurations:\n",
        "\n",
        "Configuration 1\n",
        "* **Epochs:** 1\n",
        "* **Learning Rate:**\n",
        "  * 0.8\n",
        "  * 0.5\n",
        "  * 0.1\n",
        "  * 0.05\n",
        "  * 0.01\n",
        "\n",
        "Configuration 2\n",
        "* **Epochs:**\n",
        "  * 1\n",
        "  * 2\n",
        "  * 3\n",
        "  * 4\n",
        "  * 5\n",
        "* **Learning Rate:** 0.2\n",
        "\n",
        "The code will print out a Loss and Accuracy graph, so you can see how well the neural network performed.\n",
        "\n",
        "*If you're having trouble solving problem 3, you can view the solution [here](intro_to_tensorflow_solution.ipynb).*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Eksplorasi**: Selanjutnya masuk kedalam problem 3 yang dimana terdapat 2 parameter konfigurasi utnuk training neural network nya, pada masing-masing configuration, satu parameter mempunyai multiple options. Untuk setiap konfigurasi, pilih dari opsi yang memberikan best accuracy.\n",
        ">\n",
        "> Setelah training neural network dilakukan, selanjutnya dilakukan plotting grafik untuk melihat hasil pembelajarannya"
      ],
      "metadata": {
        "id": "aLoWqjK89zPZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5Nherfe-rOwB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "c8462f92-b201-4bb4-d9fc-dbf322774693"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch  1/1: 100%|██████████| 1114/1114 [00:16<00:00, 68.80batches/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy at 0.7501333355903625\n"
          ]
        }
      ],
      "source": [
        "# Change if you have memory restrictions\n",
        "batch_size = 128\n",
        "\n",
        "# TODO: Find the best parameters for each configuration\n",
        "epochs = 1\n",
        "learning_rate = 0.5\n",
        "\n",
        "### DON'T MODIFY ANYTHING BELOW ###\n",
        "# Gradient Descent\n",
        "optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
        "\n",
        "# The accuracy measured against the validation set\n",
        "validation_accuracy = 0.0\n",
        "\n",
        "# Measurements use for graphing loss and accuracy\n",
        "log_batch_step = 50\n",
        "batches = []\n",
        "loss_batch = []\n",
        "train_acc_batch = []\n",
        "valid_acc_batch = []\n",
        "\n",
        "with tf.compat.v1.Session() as session:\n",
        "    session.run(init)\n",
        "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
        "\n",
        "    for epoch_i in range(epochs):\n",
        "\n",
        "        # Progress bar\n",
        "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
        "\n",
        "        # The training cycle\n",
        "        for batch_i in batches_pbar:\n",
        "            # Get a batch of training features and labels\n",
        "            batch_start = batch_i*batch_size\n",
        "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
        "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
        "\n",
        "            # Run optimizer and get loss\n",
        "            _, l = session.run(\n",
        "                [optimizer, loss],\n",
        "                feed_dict={features: batch_features, labels: batch_labels})\n",
        "\n",
        "            # Log every 50 batches\n",
        "            if not batch_i % log_batch_step:\n",
        "                # Calculate Training and Validation accuracy\n",
        "                training_accuracy = session.run(accuracy, feed_dict=train_feed_dict)\n",
        "                validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
        "\n",
        "                # Log batches\n",
        "                previous_batch = batches[-1] if batches else 0\n",
        "                batches.append(log_batch_step + previous_batch)\n",
        "                loss_batch.append(l)\n",
        "                train_acc_batch.append(training_accuracy)\n",
        "                valid_acc_batch.append(validation_accuracy)\n",
        "\n",
        "        # Check accuracy against Validation data\n",
        "        validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
        "\n",
        "loss_plot = plt.subplot(211)\n",
        "loss_plot.set_title('Loss')\n",
        "loss_plot.plot(batches, loss_batch, 'g')\n",
        "loss_plot.set_xlim([batches[0], batches[-1]])\n",
        "acc_plot = plt.subplot(212)\n",
        "acc_plot.set_title('Accuracy')\n",
        "acc_plot.plot(batches, train_acc_batch, 'r', label='Training Accuracy')\n",
        "acc_plot.plot(batches, valid_acc_batch, 'x', label='Validation Accuracy')\n",
        "acc_plot.set_ylim([0, 1.0])\n",
        "acc_plot.set_xlim([batches[0], batches[-1]])\n",
        "acc_plot.legend(loc=4)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('Validation accuracy at {}'.format(validation_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZXu63xBrOwB"
      },
      "source": [
        "## Test\n",
        "You're going to test your model against your hold out dataset/testing data.  This will give you a good indicator of how well the model will do in the real world.  You should have a test accuracy of at least 80%."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Eksplorasi**: Setelah model di training, selanjutnya dilakukan test kepada model tersebut menggunakan kumpulan data hold out/data pengujian anda. Ini akan memberikan anda indikator yang baik tentang seberapa baik kinerja model bekerja di dunia nyata. Anda harus memiliki akurai pengujian minimal 80%."
      ],
      "metadata": {
        "id": "vBi6RSy4Cwqh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "_7K3as32rOwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c95d276-14d2-4f97-b9b6-25795e094692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch  1/1: 100%|██████████| 1114/1114 [00:01<00:00, 823.32batches/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nice Job! Test Accuracy is 0.8264999985694885\n"
          ]
        }
      ],
      "source": [
        "### DON'T MODIFY ANYTHING BELOW ###\n",
        "# The accuracy measured against the test set\n",
        "test_accuracy = 0.0\n",
        "\n",
        "with tf.compat.v1.Session() as session:\n",
        "\n",
        "    session.run(init)\n",
        "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
        "\n",
        "    for epoch_i in range(epochs):\n",
        "\n",
        "        # Progress bar\n",
        "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
        "\n",
        "        # The training cycle\n",
        "        for batch_i in batches_pbar:\n",
        "            # Get a batch of training features and labels\n",
        "            batch_start = batch_i*batch_size\n",
        "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
        "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
        "\n",
        "            # Run optimizer\n",
        "            _ = session.run(optimizer, feed_dict={features: batch_features, labels: batch_labels})\n",
        "\n",
        "        # Check accuracy against Test data\n",
        "        test_accuracy = session.run(accuracy, feed_dict=test_feed_dict)\n",
        "\n",
        "\n",
        "assert test_accuracy >= 0.80, 'Test accuracy at {}, should be equal to or greater than 0.80'.format(test_accuracy)\n",
        "print('Nice Job! Test Accuracy is {}'.format(test_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIiOw1a5rOwC"
      },
      "source": [
        "# Multiple layers\n",
        "Good job!  You built a one layer TensorFlow network!  However, you might want to build more than one layer.  This is deep learning after all!  In the next section, you will start to satisfy your need for more layers."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}